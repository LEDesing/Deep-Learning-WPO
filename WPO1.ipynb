{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEDesing/Deep-Learning-WPO/blob/main/WPO1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAlvv8v5FS6D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz7HvWzPFS6E"
      },
      "source": [
        "### PyTorch Tensors\n",
        "\n",
        "The deep learning terminology for a \"matrix\". In PyTorch, it is the basic structure to represent data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwxrzul3FS6F",
        "outputId": "a56f0522-e97f-4b6a-f506-37bbe5d32f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 1])\n",
            "torch.Size([3])\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "#This is a 1-D Tensor\n",
        "a = torch.tensor([2,2,1])\n",
        "print(a)\n",
        "# the shape of a Tensor \"a\".\n",
        "print(a.shape) # or a.size()\n",
        "# the data type of a Tensor \"a\".\n",
        "print(a.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggjbiFI7FS6F",
        "outputId": "a76c0339-aaa7-4c3e-9cc4-7302e39a5961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 1],\n",
            "        [3, 5],\n",
            "        [1, 2]])\n",
            "torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "#This is a 2-D Tensor\n",
        "b = torch.tensor([[2,1],\n",
        "                  [3,5],\n",
        "                  [1,2]])\n",
        "print(b)\n",
        "print(b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GudSRDtyFS6G",
        "outputId": "720e4460-5f93-4115-da4b-ce2d7d40dd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "2\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "# Get the number of rows of b\n",
        "print(b.shape[0])\n",
        "\n",
        "# Get the number of columns of b\n",
        "print(b.shape[1])\n",
        "\n",
        "# number of elements\n",
        "print(b.numel())\n",
        "\n",
        "assert b.numel() == b.shape[0] * b.shape[1] # pour verifier une egalit√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UZP8MeeFS6G"
      },
      "outputs": [],
      "source": [
        "# Create a Float Tensor\n",
        "b_float = torch.FloatTensor([[2,1,4],\n",
        "                             [3,5,4],\n",
        "                             [1,2,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y22M0lHIFS6H",
        "outputId": "3e9636a1-efe3-49aa-d6f8-35135311c193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 1.],\n",
            "        [3., 5.],\n",
            "        [1., 2.]])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# or convert the original b into float\n",
        "b = b.float()\n",
        "print(b)\n",
        "print(b.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCVyABvrFS6H",
        "outputId": "4f7ea064-22ff-4ef4-d191-00d2a9ffb905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3333)\n",
            "tensor(14.)\n",
            "tensor(1.5055)\n"
          ]
        }
      ],
      "source": [
        "# statistics on a tensor\n",
        "\n",
        "#Print the mean of all elements of tensor b.\n",
        "print(b.mean())\n",
        "#Print the sum of all elements of tensor b.\n",
        "print(b.sum())\n",
        "#Print the standard deviation of all elements tensor b.\n",
        "print(b.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T08HO26YFS6I",
        "outputId": "b7afb3c1-2b88-420b-c6c8-f93a0d282e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0000, 2.6667])\n",
            "tensor([1.5000, 4.0000, 1.5000])\n",
            "tensor([1.5000, 4.0000, 1.5000])\n"
          ]
        }
      ],
      "source": [
        "# statistics across dimensions\n",
        "print(b.mean(dim = 0))    # moyenne suivant les colones\n",
        "print(b.mean(dim = 1))   # moyenne suivant les ligne\n",
        "print(b.mean(dim = -1))   # moyenne suivant la derniere dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aUWOotjGFS6I",
        "outputId": "4bd4e8d6-d0ba-4767-e11b-2c89ccff6c8e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'b' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5b292b94d05c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transposing 2D tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
          ]
        }
      ],
      "source": [
        "# transposing 2D tensors\n",
        "print(b)\n",
        "b = b.t()\n",
        "print(b.shape)\n",
        "print(b.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNTz8iQAFS6I",
        "outputId": "313af82d-8405-47f0-da9c-adb4a7394aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 3., 1.],\n",
            "        [1., 5., 2.]])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "# flattening a tensor into 1D\n",
        "print(b)\n",
        "print(b.shape)\n",
        "b = b.reshape(-1)  # -1, its size can be inferred\n",
        "print(b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeLf52XAFS6I"
      },
      "outputs": [],
      "source": [
        "# create a random 3D tensor with values sampled from the normal distribution with a mean of 0 and a std of 1\n",
        "r1 = torch.randn(6,3,4)   # n stand for normal distribution (6 c'est la profondeur:  la 3eme dimension)\n",
        "\n",
        "# create a random 3D tensor with values sampled from the uniform distribution from the range 0-1\n",
        "r2 = torch.rand(6,4,3)\n",
        "\n",
        "# transpose the 3D tensor r2 to match dimensions with r1\n",
        "r2 = r2.permute(0,2,1) # pour trasposer un tenseur de dimension 3.;  0== je mentien la profondeur, 2, 1 pour transposer la matrice dim2\n",
        "# en pratique 2 devien 1 et vice versa. (1 ==rows, 2==columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFNqUIjgFS6J"
      },
      "outputs": [],
      "source": [
        "# element-weise operations (addition, multiplication, subtraction)\n",
        "print(r1 + r2)\n",
        "print(r1 * r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n5A7xhbFS6J"
      },
      "outputs": [],
      "source": [
        "# absolute value\n",
        "f = torch.randn(1,2)\n",
        "print(f)\n",
        "print(torch.abs(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQp7VY8DFS6J"
      },
      "outputs": [],
      "source": [
        "# tensor of 1s and 0s\n",
        "ones = torch.ones(3,5)\n",
        "print(ones)\n",
        "\n",
        "zeros = torch.zeros(5,2) #zeros(colum, row)\n",
        "print(zeros)\n",
        "\n",
        "# add a scalar\n",
        "zeros = zeros + 5\n",
        "print(zeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnPk-Mf4FS6J"
      },
      "outputs": [],
      "source": [
        "# random tensor with the shape and datatype of another tensor\n",
        "v = torch.randn_like(ones)\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ7PFyxfFS6J"
      },
      "source": [
        "### Matrix Multiplications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thaL_UXOFS6J"
      },
      "source": [
        "Create any two random 2D tensors, and perform a matrix multiplication. Make sure the dimensions match! Use [torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSKCKVcGFS6K",
        "outputId": "0e3d8bb7-8e03-4920-ce03-8f74b0ee0fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1380,  0.1951, -0.4190],\n",
            "        [-0.2315, -0.0476, -0.4045],\n",
            "        [ 0.0358,  0.3536,  0.4914]])\n"
          ]
        }
      ],
      "source": [
        "### SOLUTION\n",
        "t2D1 = torch.randn(3,3)\n",
        "t2D2 = torch.rand(3,3)\n",
        "mux  = t2D1*t2D2\n",
        "print(mux)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-tQr9_MFS6K"
      },
      "source": [
        "Print all the elements of the **first** column of the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeJIThSzFS6K",
        "outputId": "98ab142c-ee8d-417d-8e72-6f870a8aa2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1380, -0.2315,  0.0358])\n"
          ]
        }
      ],
      "source": [
        "### SOLUTION\n",
        "print(mux[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNg7Eoi9FS6K"
      },
      "source": [
        "Print any element (one only) from the resulting tensor. See [torch.item](https://pytorch.org/docs/stable/generated/torch.Tensor.item.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSCzYW4PFS6K",
        "outputId": "85c00844-e00e-43d0-adb7-6ef2855320c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.137994185090065, 0.19510510563850403, -0.41902390122413635], [-0.23147739470005035, -0.04759873449802399, -0.4044612646102905], [0.03577583655714989, 0.3536339998245239, 0.49136000871658325]]\n",
            "tensor(0.1951)\n",
            "0.19510510563850403\n",
            "0.19510510563850403\n"
          ]
        }
      ],
      "source": [
        "### SOLUTION\n",
        "print(mux.tolist())\n",
        "print(mux[0,1])\n",
        "print(mux[0,1].tolist())\n",
        "print(mux[0,1].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaDsndKkFS6K"
      },
      "source": [
        "Now let's create a 4D Tensor called `g`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S90pS8CFS6K"
      },
      "outputs": [],
      "source": [
        "g = torch.randn(6,7,2,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15QcLUJyFS6K"
      },
      "source": [
        "Reshape the tensor `g` to 3D to have the shape: (6,7,8). Use the [reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html) function. Try two different ways of reshaping, including specifying -1. Verify that the two ways of rehaping are equivalent, using the `assert` function in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "a4ULNXAmFS6K",
        "outputId": "3a4e569b-f8bf-4193-bea0-0b25ac9595e2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'torch.Size' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-910ff63c4dd0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
          ]
        }
      ],
      "source": [
        "### SOLUTION\n",
        "h = g.reshape(6,7,8)\n",
        "print(h.shape())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS-79X0WFS6K"
      },
      "source": [
        "Create a random 2D tensor, then extract its maximum value using [torch.max](https://pytorch.org/docs/stable/generated/torch.max.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSI3YPepFS6L"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUU2pM-_FS6L"
      },
      "source": [
        "Now extract the maximum value and the index of that value, across the **columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSkKPRyBFS6L"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dibF3qAoFS6L"
      },
      "source": [
        "Now extract the maximum value and the index of that value, across the **rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAdrIeLeFS6L"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHk87shHFS6L"
      },
      "source": [
        "### Numpy Bridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPqCFol6FS6L"
      },
      "source": [
        "Define a random PyTorch Tensor of any size you want, and convert it into numpy using [.numpy](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFhdbLztFS6L"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAgcPvKnFS6L"
      },
      "source": [
        "Now convert back the numpy tensor to PyTorch, using [torch.from_numpy](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVA5fQK5FS6M"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trusU8JKFS6M"
      },
      "source": [
        "Move the PyTorch Tensor to the GPU. When training deep learning models, everything has to be on the GPU!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN1Ko1kOFS6Q"
      },
      "outputs": [],
      "source": [
        "# move the tensor to the GPU\n",
        "a = torch.randn(5)\n",
        "print(a.device)\n",
        "CUDA = torch.cuda.is_available()\n",
        "print(CUDA)\n",
        "if CUDA:\n",
        "    a = a.cuda()\n",
        "    print(a.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgSVPuZNFS6Q"
      },
      "source": [
        "### Tensor Concatenation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uojc0BP9FS6Q"
      },
      "source": [
        "You can concatenate any two tensors along any dimension, using [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html). Make sure that the two tensors you are concatenating match along the dimension you want to concatenate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T4knXrQFS6Q"
      },
      "source": [
        "Define two 2D Tensors of random values. Afterwards, concatenate along the rows. Print the shape of the resulting tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i3zxuG8FS6Q"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHSz9gudFS6Q"
      },
      "source": [
        "Define two 2D Tensors of random values. Afterwards, concatenate along the columns. Print the shape of the resulting tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttzb56lxFS6Q"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhN7U-LOFS6R"
      },
      "source": [
        "### Adding and Removing Dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al2_K7clFS6R"
      },
      "source": [
        "In many times, we need to add a dimension to be able to operate on Tensors. We will see many cases of this during the course. This is probably the most function we will use.\n",
        "\n",
        "To add a dimension, the function is [unsqueeze](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html). To remove a dimension, the function is [squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMmT0brWFS6R"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qmz1qFvFS6R"
      },
      "source": [
        "Add a dimension at the end. Print the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qscMyk60FS6R",
        "outputId": "61ce432f-9292-420b-d66c-bb4fd1525fcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "a.shape\n",
        "#unsqueesed.squeeze(1); #unsqueesed.squeeze(-1); #unsqueesed.squeeze(0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSWDfcmkFS6R"
      },
      "source": [
        "Add another dimension at the start. Print the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xo0PKecFS6R"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrbM91wBFS6R"
      },
      "source": [
        "Add another dimension at the start (one more time). Print the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7lzjo-GFS6R"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GCXLccpFS6S"
      },
      "source": [
        "Remove the last dimension. Print the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1njGJNJFS6S"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBOpvFV8FS6S"
      },
      "source": [
        "Remove all dimensions with a 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxIbJW-CFS6S"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLQKt2QwFS6S"
      },
      "source": [
        "### Autograd (Automatic Differentiation) in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLquU8SzFS6S"
      },
      "source": [
        "Remember we need to tell PyTorch which gradients we want!\n",
        "If we dont explicilty tell it, PyTorch will not track gradients!\n",
        "\n",
        "Let's create some operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcumhnTSFS6S"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1., 2., 3., 4., 5.])\n",
        "y = x**2\n",
        "z = torch.sum(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTiDbKIVFS6S"
      },
      "source": [
        "Every Tensor has a `requires_grad` attrbiute which tells us if the tensor needs gradients. It also has a `grad_fn` attribute that tells you what the funtion is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cOheQ1zFS6S"
      },
      "outputs": [],
      "source": [
        "print(x.requires_grad)\n",
        "print(z.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fQZbfOfFS6S"
      },
      "source": [
        "1. Now create the same tensor, but this time it should require gradients (gradients should be computed with respect to it). Perform the same operations as above on that Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZQLSVP0FS6T"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648cStkRFS6T"
      },
      "source": [
        "2. Check the gradient function. Does PyTorch know how z was created? Did it record the computation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5g_I49yFS6T"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nti6EYoFS6T"
      },
      "source": [
        "3. Check which tensors (`x`,`y`,`z`) requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRjGNmMrFS6T"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ad17kGgFS6T"
      },
      "source": [
        "We can access the gradient of any tensor using the `grad` attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBR7eEABFS6T"
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwjWGDj2FS6T"
      },
      "source": [
        "As we see, it is `None`. The function `backward` computes the gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qG5KnSxFS6T"
      },
      "outputs": [],
      "source": [
        "z.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olm-FjiaFS6U"
      },
      "source": [
        "Do the same thing (check the gradients) of `y`. What do you realize?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0IVnsg3FS6U"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yInqSvsFFS6U"
      },
      "source": [
        "`y` is an intermediate variable. PyTorch does NOT keep gradients of intermediate tensors in order to save memory. If we wanted the gradient with respect to `y`, we need to tell PyTorch to track it through the `retain_grad` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx-rteIfFS6U"
      },
      "outputs": [],
      "source": [
        "y.retain_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9OUIBzvFS6U"
      },
      "source": [
        "But now if we find the gradient of `y`, we get an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_UWWMTHFS6U"
      },
      "outputs": [],
      "source": [
        "z.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdXcylFjFS6U"
      },
      "source": [
        "That is because the computation graph is destroyed after the backward call! You need to tell PyTorch that you want it to compute gradients w.r.t `y`, **before** you call the backward function. We can use the [retain grad](https://pytorch.org/docs/stable/generated/torch.Tensor.retain_grad.html) function for this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pflCTfKDFS6U"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdOfcWYQFS6U"
      },
      "source": [
        "**Note FYI:** You can also keep the graph (avoid PyTorch from destroying it after the backward call) using `retrain_graph = True` when calling the backward function. However, we will almost never use this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEmpO4cgFS6V"
      },
      "source": [
        "the `detach` function tells PyTorch to forget the computation history. It is very helpful to free memory! Saves you 50% of the problems. It returns a copy of the tensor but with the computation history forgotten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGp9QkrpFS6V"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1., 2., 3., 4., 5.], requires_grad=True)\n",
        "y = x * 2\n",
        "z = torch.sum(y)\n",
        "print(z.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1NGGFV2FS6V"
      },
      "source": [
        "Now forget the computation history of the variable `z`. Verify that it is forgotten using `grad_fn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozRu4Vt0FS6V"
      },
      "outputs": [],
      "source": [
        "### SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urXAhoipFS6V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}